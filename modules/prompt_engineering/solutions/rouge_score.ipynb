{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Added notebook directory to Python path:\n",
      "   /workspaces/llmops-course/modules/prompt_engineering/solutions\n",
      "   You can now import modules from this directory\n",
      "‚ö†Ô∏è Warning: Failed to set up notebook path\n",
      "üîÑ Initializing Course environment...\n",
      "üîÅ Autoreload enabled: modules will reload automatically when changed\n",
      "üîï Suppressed future deprecation warnings\n",
      "üìù Logging configured\n",
      "üìä Pandas display settings configured for better output\n",
      "üîç Looking for .env file at: /workspaces/llmops-course/.env\n",
      "‚úÖ Successfully loaded environment variables from /workspaces/llmops-course/.env\n",
      "üìã Loaded variables: GEMINI_API_KEY=****sbqo\n",
      "‚öôÔ∏è Disabled MLflow system metrics logging\n",
      "üìî Disabled MLflow notebook display (avoids VSCode bugs)\n",
      "\n",
      "================================================================================\n",
      "üéâ All systems go! Your Course environment is ready for learning!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import helpers\n",
    "helpers.initialize(notebook_path=__vsc_ipynb_file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Rouge Scorer at: http://localhost:5050/#/experiments/0/runs/4c93a859a7284e9b91a15a239863a03f\n",
      "üß™ View experiment at: http://localhost:5050/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from rouge_score import rouge_scorer\n",
    "from textsummarizer import TextSummarizer\n",
    "\n",
    "def rouge_metrics(reference, prediction):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, prediction)\n",
    "    \n",
    "    return scores['rouge1'].fmeasure\n",
    "\n",
    "with mlflow.start_run(run_name=\"Rouge Scorer\"):\n",
    "    path = 'assets/articles_full_length/ai_relationships.html'\n",
    "    text = open(path).read()\n",
    "\n",
    "    prompt = \"Summarize this article: {text}\"\n",
    "    max_output_tokens = 1000\n",
    "\n",
    "    mlflow.log_param(\"max_output_tokens\", max_output_tokens)\n",
    "    mlflow.log_param(\"prompt\", prompt)\n",
    "    mlflow.log_param(\"path\", path)\n",
    "    mlflow.log_text(text, \"original_text.txt\")\n",
    "\n",
    "    summarizer = TextSummarizer(prompt = prompt, max_output_tokens=max_output_tokens)\n",
    "    summary = summarizer.summarize(text)\n",
    "\n",
    "    mlflow.log_text(summary, \"summary.txt\")\n",
    "\n",
    "    mlflow.log_metric(\"summary_length\", len(summary))\n",
    "\n",
    "    rouge_f1 = rouge_metrics(text, summary)\n",
    "    mlflow.log_metric(\"rouge1_f1\", rouge_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Rouge Scorer at: http://localhost:5050/#/experiments/0/runs/83b45e9f770346f8b876e5c3d767d547\n",
      "üß™ View experiment at: http://localhost:5050/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from rouge_score import rouge_scorer\n",
    "from textsummarizer import TextSummarizer\n",
    "\n",
    "def rouge_metrics(reference, prediction):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, prediction)\n",
    "    \n",
    "    return scores['rouge1'].fmeasure\n",
    "\n",
    "with mlflow.start_run(run_name=\"Rouge Scorer\"):\n",
    "    path = 'assets/articles_full_length/ai_relationships.html'\n",
    "    text = open(path).read()\n",
    "\n",
    "    prompt = \"Extract the most important information from this article, covering all key points, main arguments, and conclusions. Include relevant phrases from the original text: {text}\"\n",
    "    max_output_tokens = 1000\n",
    "\n",
    "    mlflow.log_param(\"prompt\", prompt)\n",
    "    mlflow.log_param(\"path\", path)\n",
    "    mlflow.log_text(text, \"original_text.txt\")\n",
    "\n",
    "    summarizer = TextSummarizer(prompt = prompt)\n",
    "    summary = summarizer.summarize(text)\n",
    "\n",
    "    mlflow.log_text(summary, \"summary.txt\")\n",
    "\n",
    "    mlflow.log_metric(\"summary_length\", len(summary))\n",
    "\n",
    "    rouge_f1 = rouge_metrics(text, summary)\n",
    "    mlflow.log_metric(\"rouge1_f1\", rouge_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Link Summary Basic at: http://localhost:5050/#/experiments/0/runs/90aa7e8263164113be058bd14e4fc053\n",
      "üß™ View experiment at: http://localhost:5050/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from rouge_score import rouge_scorer\n",
    "from textsummarizer import TextSummarizer\n",
    "\n",
    "def rouge_metrics(reference, prediction):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, prediction)\n",
    "    \n",
    "    return scores['rouge1'].fmeasure\n",
    "\n",
    "with mlflow.start_run(run_name=\"Link Summary Basic\"):\n",
    "    path = 'assets/articles_full_length/ai_relationships.html'\n",
    "    text = open(path).read()\n",
    "\n",
    "    prompt = \"\"\"Create a brief preview of the web page content in 50-75 words. Focus on what a reader would want to know before clicking:\n",
    "{text}\"\"\"\n",
    "    max_output_tokens = 150\n",
    "\n",
    "    mlflow.log_param(\"prompt\", prompt)\n",
    "    mlflow.log_param(\"path\", path)\n",
    "    mlflow.log_text(text, \"original_text.txt\")\n",
    "\n",
    "    summarizer = TextSummarizer(prompt = prompt)\n",
    "    summary = summarizer.summarize(text)\n",
    "\n",
    "    mlflow.log_text(summary, \"summary.txt\")\n",
    "\n",
    "    mlflow.log_metric(\"summary_length\", len(summary))\n",
    "\n",
    "    rouge_f1 = rouge_metrics(text, summary)\n",
    "    mlflow.log_metric(\"rouge1_f1\", rouge_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Link Summary Optimized at: http://localhost:5050/#/experiments/0/runs/e462d309536948d885b47101d01d9330\n",
      "üß™ View experiment at: http://localhost:5050/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from rouge_score import rouge_scorer\n",
    "from textsummarizer import TextSummarizer\n",
    "\n",
    "def rouge_metrics(reference, prediction):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, prediction)\n",
    "    \n",
    "    return scores['rouge1'].fmeasure\n",
    "\n",
    "with mlflow.start_run(run_name=\"Link Summary Optimized\"):\n",
    "    path = 'assets/articles_full_length/ai_relationships.html'\n",
    "    text = open(path).read()\n",
    "\n",
    "    prompt = \"\"\"Extract the essence of this web content in exactly 4 bullet points (total under 100 words):\n",
    "\n",
    "    1. üîç **Focus:** [Main topic/purpose in 5-7 words]\n",
    "    2. üì∞ **Content:** [Key information in 5-7 words]\n",
    "    3. üéØ **Tone:** [Style/perspective in 5-7 words]\n",
    "    4. üë• **Value:** [User benefit in 5-7 words]\n",
    "\n",
    "    Use exact phrases from the original where possible to increase content overlap. Keep descriptions under 7 words each. Maintain the exact formatting with emoji, bold categories, and brief descriptions:\n",
    "    {text}\"\"\"\n",
    "\n",
    "    max_output_tokens = 200\n",
    "\n",
    "    mlflow.log_param(\"prompt\", prompt)\n",
    "    mlflow.log_param(\"path\", path)\n",
    "    mlflow.log_text(text, \"original_text.txt\")\n",
    "\n",
    "    summarizer = TextSummarizer(prompt = prompt)\n",
    "    summary = summarizer.summarize(text)\n",
    "\n",
    "    mlflow.log_text(summary, \"summary.txt\")\n",
    "\n",
    "    mlflow.log_metric(\"summary_length\", len(summary))\n",
    "\n",
    "    rouge_f1 = rouge_metrics(text, summary)\n",
    "    mlflow.log_metric(\"rouge1_f1\", rouge_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve the rouge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from rouge_score import rouge_scorer\n",
    "from textsummarizer import TextSummarizer\n",
    "\n",
    "def rouge_metrics(reference, prediction):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    scores = scorer.score(reference, prediction)\n",
    "    \n",
    "    return scores['rouge1'].fmeasure\n",
    "\n",
    "with mlflow.start_run(run_name=\"Link Summary Optimized\"):\n",
    "    path = 'assets/articles_full_length/ai_relationships.html'\n",
    "    text = open(path).read()\n",
    "\n",
    "    prompt = \"\"\"Extract the essence of this web content in exactly 4 bullet points (total under 200 words):\n",
    "\n",
    "    1. üîç **Focus:** [Main topic/purpose in 15-20 words]\n",
    "    2. üì∞ **Content:** [Key information in 15-20 words]\n",
    "    3. üéØ **Tone:** [Style/perspective in 5-7 words]\n",
    "    4. üë• **Value:** [User benefit in 5-7 words]\n",
    "\n",
    "    Use exact phrases from the original where possible to increase content overlap. Keep descriptions under 7 words each. Maintain the exact formatting with emoji, bold categories, and brief descriptions:\n",
    "    {text}\"\"\"\n",
    "\n",
    "    max_output_tokens = 300\n",
    "\n",
    "    mlflow.log_param(\"prompt\", prompt)\n",
    "    mlflow.log_param(\"path\", path)\n",
    "    mlflow.log_text(text, \"original_text.txt\")\n",
    "\n",
    "    summarizer = TextSummarizer(prompt = prompt)\n",
    "    summary = summarizer.summarize(text)\n",
    "\n",
    "    mlflow.log_text(summary, \"summary.txt\")\n",
    "\n",
    "    mlflow.log_metric(\"summary_length\", len(summary))\n",
    "\n",
    "    rouge_f1 = rouge_metrics(text, summary)\n",
    "    mlflow.log_metric(\"rouge1_f1\", rouge_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### üöÄ RUN ME BEFORE YOU START WORKING ON THIS NOTEBOOK ‚ö†Ô∏è\n",
    "\n",
    "import helpers\n",
    "NOTEBOOK_PATH = __vsc_ipynb_file__ # type: ignore\n",
    "helpers.initialize(notebook_path=NOTEBOOK_PATH)\n",
    "\n",
    "### üöÄ RUN ME BEFORE YOU START WORKING ON THIS NOTEBOOK ‚ö†Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Recursively find all HTML files in assets directory\n",
    "html_files = glob.glob(\"assets/articles_short/*.html\")\n",
    "\n",
    "# Create list to store file data\n",
    "file_data = []\n",
    "\n",
    "# Read each HTML file\n",
    "for file_path in html_files:\n",
    "    content = open(file_path, 'r', encoding='utf-8').read()\n",
    "    file_data.append({\n",
    "        'file_name': Path(file_path).name,\n",
    "        'text': content\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(file_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textsummarizer import SerializableArticleSummarizerModel\n",
    "\n",
    "m = SerializableArticleSummarizerModel()\n",
    "df[\"summaries\"] = m.predict(df)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"LLM Evaluation\") as run:\n",
    "    eval_result = mlflow.evaluate(\n",
    "        data=df,\n",
    "        predictions=\"summaries\",\n",
    "        targets=\"text\",\n",
    "        model_type=\"text-summarization\",\n",
    "        extra_metrics=[\n",
    "            mlflow.metrics.token_count(),\n",
    "        ],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.metrics import MetricValue, make_metric\n",
    "from mlflow.metrics.base import standard_aggregations\n",
    "from textsummarizer import REFUSAL_TEXT\n",
    "\n",
    "def model_refused_to_respond(predictions, targets):\n",
    "    scores = []\n",
    "    for prediction in predictions:\n",
    "        if prediction == REFUSAL_TEXT:\n",
    "            scores.append(1)\n",
    "        else:\n",
    "            scores.append(0)\n",
    "\n",
    "    return MetricValue(\n",
    "        scores=scores,\n",
    "        aggregate_results=standard_aggregations(scores),\n",
    "    )\n",
    "\n",
    "\n",
    "# Create an EvaluationMetric object.\n",
    "refusal_rate_metric = make_metric(\n",
    "    eval_fn=model_refused_to_respond, greater_is_better=False, name=\"refusal_rate\"\n",
    ")\n",
    "\n",
    "print(model_refused_to_respond(df[\"summaries\"], df[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"LLM Evaluation\") as run:\n",
    "    eval_result = mlflow.evaluate(\n",
    "        data=df,\n",
    "        predictions=\"summaries\",\n",
    "        targets=\"text\",\n",
    "        model_type=\"text-summarization\",\n",
    "        extra_metrics=[\n",
    "            refusal_rate_metric\n",
    "        ],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

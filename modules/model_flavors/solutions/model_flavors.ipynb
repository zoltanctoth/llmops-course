{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è Notebook directory already in Python path:\n",
      "   /workspaces/llmops-course/modules/model_flavors/solutions\n",
      "‚ö†Ô∏è Warning: Failed to set up notebook path\n",
      "üîÑ Environment already initialized. Skipping...\n"
     ]
    }
   ],
   "source": [
    "import helpers\n",
    "helpers.initialize(notebook_path=__vsc_ipynb_file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"1. üîç **Focus:** AI's impact on relationships, from personal to professional\\n2. üì∞ **Content:** Individuals are using AI chatbots for emotional support, navigating relationships, and enhancing self-care, as well as for creative projects and language learning.\\n3. üéØ **Tone:** Informative, optimistic\\n4. üë• **Value:**  Provides real-world examples of AI's potential in diverse relationships and problem-solving.\\n\"]\n"
     ]
    }
   ],
   "source": [
    "from textsummarizer import ArticleSummarizerModel\n",
    "\n",
    "m = ArticleSummarizerModel()\n",
    "\n",
    "predictions = m.predict([{'text': text}])\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/03 12:24:57 INFO mlflow.models.signature: Inferring model signature from type hints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Article Summarizer at: http://localhost:5050/#/experiments/0/runs/b1aae9a95f5a4791b56488d177c5b6ef\n",
      "üß™ View experiment at: http://localhost:5050/#/experiments/0\n",
      "Failed to serialize Python model. Please save the model into a python file and use code-based logging method instead. Seehttps://mlflow.org/docs/latest/models.html#models-from-code for more information.\n"
     ]
    }
   ],
   "source": [
    "# This is expected to fail as  google.generativeai.GenerativeModel is not serializable\n",
    "import mlflow\n",
    "\n",
    "path = 'assets/articles_full_length/ai_relationships.html'\n",
    "text = open(path).read()\n",
    "\n",
    "try:\n",
    "    with mlflow.start_run(run_name=\"Article Summarizer\") as run:\n",
    "        mlflow.pyfunc.log_model(\n",
    "            \"article_summarizer\",\n",
    "            python_model=m,\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make this serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/03 12:26:55 INFO mlflow.models.signature: Inferring model signature from type hints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Article Summarizer at: http://localhost:5050/#/experiments/0/runs/027935227a234bd7af8da0a1aef53a26\n",
      "üß™ View experiment at: http://localhost:5050/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from textsummarizer import SerializableArticleSummarizerModel\n",
    "\n",
    "path = 'assets/articles_full_length/ai_relationships.html'\n",
    "text = open(path).read()\n",
    "\n",
    "m = SerializableArticleSummarizerModel()\n",
    "\n",
    "with mlflow.start_run(run_name=\"Article Summarizer\") as run:\n",
    "    mlflow.pyfunc.log_model(\n",
    "        \"article_summarizer\",\n",
    "        python_model=m,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make this a proper mlflow model for logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.12/site-packages/mlflow/types/type_hints.py:221: UserWarning: \u001b[1;33mAny type hint is inferred as AnyType, and MLflow doesn't validate the data for this type. Please use a more specific type hint to enable data validation.\u001b[0m\n",
      "  dtype=Map(_infer_colspec_type_from_type_hint(type_hint=args[1]).dtype),\n",
      "[autoreload of textsummarizer failed: Traceback (most recent call last):\n",
      "  File \"/home/vscode/.local/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/vscode/.local/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/vscode/.local/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/vscode/.local/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 349, in update_class\n",
      "    if update_generic(old_obj, new_obj):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/vscode/.local/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/vscode/.local/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: predict() requires a code object with 3 free vars, not 1\n",
      "]\n",
      "2025/03/03 12:44:34 INFO mlflow.pyfunc: Inferring model signature from input example\n",
      "2025/03/03 12:44:42 INFO mlflow.models.model: Found the following environment variables used during model inference: [GEMINI_API_KEY]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Article Summarizer at: http://localhost:5050/#/experiments/0/runs/d043aa336f794d54822920a82db70c90\n",
      "üß™ View experiment at: http://localhost:5050/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from textsummarizer import SerializableArticleSummarizerModel\n",
    "import pandas as pd\n",
    "\n",
    "path = 'assets/articles_full_length/ai_relationships.html'\n",
    "text = open(path).read()\n",
    "\n",
    "input_example = pd.DataFrame({'text': [text]})\n",
    "\n",
    "m = SerializableArticleSummarizerModel()\n",
    "\n",
    "with mlflow.start_run(run_name=\"Article Summarizer\") as run:\n",
    "    mlflow.pyfunc.log_model(\n",
    "        \"article_summarizer\",\n",
    "        python_model=m,\n",
    "        input_example=input_example,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/03 13:01:08 INFO mlflow.pyfunc: Validating input example against model signature\n",
      "2025/03/03 13:01:15 INFO mlflow.models.model: Found the following environment variables used during model inference: [GEMINI_API_KEY]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Article Summarizer at: http://localhost:5050/#/experiments/0/runs/5f96477a938941d380a3f427c66c8010\n",
      "üß™ View experiment at: http://localhost:5050/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from textsummarizer import SerializableArticleSummarizerModel\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = 'assets/articles_full_length/ai_relationships.html'\n",
    "text = open(path).read()\n",
    "\n",
    "input_example = pd.DataFrame({'text': [text]})\n",
    "\n",
    "m = SerializableArticleSummarizerModel()\n",
    "\n",
    "with mlflow.start_run(run_name=\"Article Summarizer\") as run:\n",
    "    mlflow.pyfunc.log_model(\n",
    "        \"article_summarizer2\",\n",
    "        python_model=m,\n",
    "        input_example=input_example,\n",
    "        signature=mlflow.models.infer_signature(\n",
    "            input_example,\n",
    "            m.predict(input_example)\n",
    "        ),\n",
    "\n",
    "        code_paths=[os.path.dirname(__vsc_ipynb_file__)],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
